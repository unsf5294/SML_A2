{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3363acad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, random, math, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Notebook / Windows safety\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "try:\n",
    "    torch.multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pin = (device == \"cuda\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e2373e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = dict(\n",
    "    csv_path=\"data/encoder_data.csv\",\n",
    "    embed_data_path = \"data/data.csv\",            \n",
    "    outdir=\"data\", \n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    epochs=6,\n",
    "    batch_size=128,\n",
    "    seq_len=128,\n",
    "    lr_enc=1e-4,\n",
    "    lr_head=5e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    seed=42,\n",
    "    freeze_bottom_layers=0,\n",
    "    tau=0.2,\n",
    "    lambda_supcon=1.0,\n",
    "    use_source_multilevel=True\n",
    ")\n",
    "os.makedirs(CFG[\"outdir\"], exist_ok=True)\n",
    "os.makedirs(os.path.join(CFG[\"outdir\"], \"ckpt\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a30e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-12):\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    return x / np.maximum(n, eps)\n",
    "\n",
    "def pool_mean(last_hidden_state, attention_mask):\n",
    "    # mean pooling with mask\n",
    "    mask = attention_mask.unsqueeze(-1).float()\n",
    "    summed = torch.sum(last_hidden_state * mask, dim=1)\n",
    "    denom = mask.sum(dim=1).clamp(min=1e-6)\n",
    "    return summed / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "824972d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tok, max_len: int):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tok = tok\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        enc = self.tok(\n",
    "            str(row[\"text\"]),\n",
    "            truncation=True, padding=\"max_length\",\n",
    "            max_length=self.max_len, return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(int(row[\"label\"]), dtype=torch.long),\n",
    "            \"src\": str(row.get(\"src\", \"\")),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fedb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, d_in: int, d_hidden: int = 256, d_out: int = 384, p_drop: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, d_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(d_hidden, d_out),\n",
    "        )\n",
    "        self.cls = nn.Linear(d_out, 2)\n",
    "\n",
    "    def forward(self, feat, return_feat: bool = False):\n",
    "        z = self.net(feat)\n",
    "        z = F.normalize(z, p=2, dim=1)\n",
    "        if return_feat:\n",
    "            return z\n",
    "        logits = self.cls(z)\n",
    "        return logits, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74427bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supcon_loss(z, y, src_list, tau: float = 0.2, use_source_multilevel: bool = True):\n",
    "    # z: (B,D) L2-normalized\n",
    "    sim = (z @ z.T) / tau               # (B,B)\n",
    "    B = z.size(0)\n",
    "    device = z.device\n",
    "\n",
    "    labels = y.view(-1, 1)              # (B,1)\n",
    "    mask_pos = (labels == labels.T)     # positives: same class\n",
    "    mask_self = torch.eye(B, device=device, dtype=torch.bool)\n",
    "    mask_pos = mask_pos & (~mask_self)\n",
    "\n",
    "    # exclude self from denom\n",
    "    sim = sim - 1e9 * mask_self.float()\n",
    "\n",
    "    # positive weights\n",
    "    pos_w = torch.ones_like(sim)\n",
    "    if use_source_multilevel and isinstance(src_list, list):\n",
    "        src_eq = torch.zeros_like(sim, dtype=torch.bool)\n",
    "        for i in range(B):\n",
    "            si = src_list[i]\n",
    "            for j in range(B):\n",
    "                if i != j and si == src_list[j]:\n",
    "                    src_eq[i, j] = True\n",
    "        both_ai = (labels == 1) & (labels.T == 1)\n",
    "        boost = (src_eq & both_ai)\n",
    "        pos_w = pos_w + 0.5 * boost.float()  # +50% on same-source AI pairs\n",
    "\n",
    "    log_prob = sim - torch.logsumexp(sim, dim=1, keepdim=True)\n",
    "    loss_mat = -log_prob * mask_pos.float() * pos_w\n",
    "    denom = mask_pos.float().sum(dim=1).clamp(min=1.0)\n",
    "    loss_per_anchor = loss_mat.sum(dim=1) / denom\n",
    "    return loss_per_anchor.mean()\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    y_true = y_true.astype(int); y_pred = y_pred.astype(int)\n",
    "    acc = float((y_true == y_pred).mean())\n",
    "\n",
    "    def prf_for(label):\n",
    "        tp = int(((y_pred == label) & (y_true == label)).sum())\n",
    "        fp = int(((y_pred == label) & (y_true != label)).sum())\n",
    "        fn = int(((y_pred != label) & (y_true == label)).sum())\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "        recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        f1        = 2*precision*recall / (precision + recall) if (precision + recall) else 0.0\n",
    "        return precision, recall, f1\n",
    "\n",
    "    p1, r1, f1 = prf_for(1)\n",
    "    _, r0, _   = prf_for(0)\n",
    "    avgrec = (r0 + r1) / 2.0\n",
    "    return {\"accuracy\": acc, \"precision_ai(1)\": p1, \"recall_ai(1)\": r1, \"f1_ai(1)\": f1,\n",
    "            \"recall_human(0)\": r0, \"avgrec\": avgrec}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7cd2eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['text', 'label', 'src']\n",
      "Rows: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manning finished the year with a career-low 67...</td>\n",
       "      <td>0</td>\n",
       "      <td>squad_machine_continuation_30B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let's not forget the traditional argument with...</td>\n",
       "      <td>0</td>\n",
       "      <td>xsum_machine_continuation_t0_3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[title] Test dye a small patch of your running...</td>\n",
       "      <td>1</td>\n",
       "      <td>hswag_human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Manning finished the year with a career-low 67...      0   \n",
       "1  Let's not forget the traditional argument with...      0   \n",
       "2  [title] Test dye a small patch of your running...      1   \n",
       "\n",
       "                               src  \n",
       "0   squad_machine_continuation_30B  \n",
       "1  xsum_machine_continuation_t0_3b  \n",
       "2                      hswag_human  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(CFG[\"seed\"])\n",
    "\n",
    "df = pd.read_csv(CFG[\"csv_path\"])\n",
    "print(\"Columns:\", list(df.columns))\n",
    "for col in (\"text\", \"label\", \"src\"):\n",
    "    assert col in df.columns, f\"Missing required column: {col}\"\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df[\"src\"]  = df[\"src\"].fillna(\"\").astype(str)\n",
    "print(\"Rows:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5562f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stratified_split(indices, labels, test_size=0.2, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.array(indices); labels = np.array(labels)\n",
    "    train_idx, val_idx = [], []\n",
    "    for lab in np.unique(labels):\n",
    "        lab_idx = indices[labels == lab]\n",
    "        rng.shuffle(lab_idx)\n",
    "        n_val = max(1, int(round(len(lab_idx) * test_size)))\n",
    "        val_idx.extend(lab_idx[:n_val].tolist())\n",
    "        train_idx.extend(lab_idx[n_val:].tolist())\n",
    "    rng.shuffle(train_idx); rng.shuffle(val_idx)\n",
    "    return np.array(train_idx), np.array(val_idx)\n",
    "\n",
    "idx_all = np.arange(len(df))\n",
    "train_idx, val_idx = stratified_split(idx_all, df[\"label\"].to_numpy(), test_size=0.2, seed=CFG[\"seed\"])\n",
    "len(train_idx), len(val_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9653f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(CFG[\"model_name\"])\n",
    "enc = AutoModel.from_pretrained(CFG[\"model_name\"]).to(device)\n",
    "\n",
    "if CFG[\"freeze_bottom_layers\"] > 0 and hasattr(enc, \"encoder\") and hasattr(enc.encoder, \"layer\"):\n",
    "    n = len(enc.encoder.layer)\n",
    "    k = max(0, min(CFG[\"freeze_bottom_layers\"], n))\n",
    "    for i in range(k):\n",
    "        for p in enc.encoder.layer[i].parameters():\n",
    "            p.requires_grad = False\n",
    "    print(f\"Froze bottom {k} / {n} transformer blocks.\")\n",
    "\n",
    "head = ProjectionHead(d_in=enc.config.hidden_size, d_hidden=256, d_out=384, p_drop=0.1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fc9eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': (<class 'torch.Tensor'>, torch.Size([2, 128])), 'attention_mask': (<class 'torch.Tensor'>, torch.Size([2, 128])), 'labels': (<class 'torch.Tensor'>, torch.Size([2])), 'src': (<class 'list'>, None)}\n",
      "src example: ['squad_machine_continuation_30B', 'xsum_machine_continuation_t0_3b']\n"
     ]
    }
   ],
   "source": [
    "train_ds = TextDataset(df.iloc[train_idx], tok, CFG[\"seq_len\"])\n",
    "val_ds   = TextDataset(df.iloc[val_idx],   tok, CFG[\"seq_len\"])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], shuffle=True,  num_workers=0, pin_memory=pin)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=0, pin_memory=pin)\n",
    "\n",
    "probe = next(iter(DataLoader(TextDataset(df.iloc[:4], tok, CFG[\"seq_len\"]),\n",
    "                             batch_size=2, shuffle=False, num_workers=0)))\n",
    "print({k: (type(v), getattr(v, 'shape', None)) for k,v in probe.items()})\n",
    "print(\"src example:\", probe[\"src\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dc0b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_params  = [p for p in enc.parameters() if p.requires_grad]\n",
    "head_params = list(head.parameters())\n",
    "opt = torch.optim.AdamW([\n",
    "    {\"params\": enc_params,  \"lr\": CFG[\"lr_enc\"]},\n",
    "    {\"params\": head_params, \"lr\": CFG[\"lr_head\"]},\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "total_steps = CFG[\"epochs\"] * max(1, len(train_loader))\n",
    "warmup_steps = int(CFG[\"warmup_ratio\"] * total_steps)\n",
    "sched = get_linear_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
    "\n",
    "# GradScaler: try new API, fallback to old if needed\n",
    "try:\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(device == \"cuda\"))\n",
    "except TypeError:\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ce42906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c18e4fe666446c4b4cd0070aab23711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c48d1a06770455ca06e71d8e3db9e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/6:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6eceb681084f4ca87bb3dc21e0b5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   1/6:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train_loss=5.6050  val_loss=0.6176  Acc=0.6470  AvgRec=0.5000  F1_AI=0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0388b0f73e4327967a70a8ab9fc752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/6:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028334da56b9486b89f81caca9009b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   2/6:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train_loss=5.4390  val_loss=0.4928  Acc=0.8055  AvgRec=0.7477  F1_AI=0.6667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f97beb0eaa46f9b26b4d57ad5843f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/6:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c9d046e48647b7a06b708c0e9bfdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   3/6:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train_loss=5.0800  val_loss=0.4277  Acc=0.8265  AvgRec=0.7790  F1_AI=0.7153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d856d53443e444eab97919186121c8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/6:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e2b533b4584f2e80540e87e9c68845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   4/6:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train_loss=4.7181  val_loss=0.4446  Acc=0.8125  AvgRec=0.7544  F1_AI=0.6770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849f72fdd4644c5e9cde73020f4bba6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/6:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5f5192f35d4f69a790468e2e4c6b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   5/6:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] train_loss=4.5407  val_loss=0.4301  Acc=0.8230  AvgRec=0.7828  F1_AI=0.7204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0611a88f6634854826ac631e4e49b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/6:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe58b03328345acbff6abf7e6fbefaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   6/6:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] train_loss=4.4329  val_loss=0.4715  Acc=0.8175  AvgRec=0.7701  F1_AI=0.7020\n",
      "Saved checkpoint: data\\ckpt\\best.pt   (AvgRec best: 0.7828)\n"
     ]
    }
   ],
   "source": [
    "best_sel = -1.0\n",
    "best_state = None\n",
    "\n",
    "for ep in tqdm(range(1, CFG[\"epochs\"]+1), desc=\"Epochs\", leave=True):\n",
    "    # ---- Train ----\n",
    "    enc.train(); head.train()\n",
    "    tr_loss, n_tr = 0.0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Train {ep}/{CFG['epochs']}\", leave=False)\n",
    "    for batch in pbar:\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        sources = batch.get(\"src\", [\"\"] * labels.size(0))\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(device == \"cuda\")):\n",
    "            out  = enc(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            feat = pool_mean(out.last_hidden_state, attention_mask)\n",
    "            logits, z = head(feat)\n",
    "            ce  = F.cross_entropy(logits, labels)\n",
    "            scl = supcon_loss(z, labels, sources, tau=CFG[\"tau\"], use_source_multilevel=CFG[\"use_source_multilevel\"])\n",
    "            loss = ce + CFG[\"lambda_supcon\"] * scl\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        sched.step()\n",
    "\n",
    "        tr_loss += loss.item() * labels.size(0)\n",
    "        n_tr    += labels.size(0)\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", ce=f\"{ce.item():.4f}\", scl=f\"{scl.item():.4f}\")\n",
    "\n",
    "    # ---- Validate ----\n",
    "    enc.eval(); head.eval()\n",
    "    y_true, y_pred, vl_loss, n_vl = [], [], 0.0, 0\n",
    "    pbar_val = tqdm(val_loader, desc=f\"Val   {ep}/{CFG['epochs']}\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar_val:\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(device == \"cuda\")):\n",
    "                out  = enc(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                feat = pool_mean(out.last_hidden_state, attention_mask)\n",
    "                logits, z = head(feat)\n",
    "                ce  = F.cross_entropy(logits, labels)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "            y_pred.append(preds.cpu().numpy())\n",
    "            vl_loss += ce.item() * labels.size(0)\n",
    "            n_vl    += labels.size(0)\n",
    "\n",
    "    y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "    mets = compute_metrics(y_true, y_pred)\n",
    "    avg_tr = tr_loss / max(1, n_tr)\n",
    "    avg_vl = vl_loss / max(1, n_vl)\n",
    "    print(f\"[Epoch {ep}] train_loss={avg_tr:.4f}  val_loss={avg_vl:.4f}  \"\n",
    "          f\"Acc={mets['accuracy']:.4f}  AvgRec={mets['avgrec']:.4f}  F1_AI={mets['f1_ai(1)']:.4f}\")\n",
    "\n",
    "    # Select by balanced recall\n",
    "    if mets[\"avgrec\"] > best_sel:\n",
    "        best_sel = mets[\"avgrec\"]\n",
    "        best_state = {\n",
    "            \"encoder\": enc.state_dict(),\n",
    "            \"head\": head.state_dict(),\n",
    "            \"val_metrics\": mets,\n",
    "            \"config\": CFG\n",
    "        }\n",
    "\n",
    "# Save best\n",
    "ckpt_path = os.path.join(CFG[\"outdir\"], \"ckpt\", \"best.pt\")\n",
    "torch.save(best_state, ckpt_path)\n",
    "print(\"Saved checkpoint:\", ckpt_path, \"  (AvgRec best:\", f\"{best_sel:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44f25252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven\\AppData\\Local\\Temp\\ipykernel_4860\\2196016986.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4490966f84c4d3e81c0c3b34db269cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export 384-d:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to: data\\text_embeddings_detective.npy\n"
     ]
    }
   ],
   "source": [
    "# Reload best (just to be sure)\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "enc.load_state_dict(state[\"encoder\"]); head.load_state_dict(state[\"head\"])\n",
    "enc.eval(); head.eval()\n",
    "\n",
    "df_eval = pd.read_csv(\"data/data.csv\")\n",
    "\n",
    "full_loader = DataLoader(TextDataset(df_eval, tok, CFG[\"seq_len\"]),\n",
    "                         batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=0, pin_memory=pin)\n",
    "\n",
    "all_chunks = []\n",
    "for batch in tqdm(full_loader, desc=\"Export 384-d\", leave=True):\n",
    "    with torch.no_grad(), torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(device == \"cuda\")):\n",
    "        out  = enc(input_ids=batch[\"input_ids\"].to(device),\n",
    "                   attention_mask=batch[\"attention_mask\"].to(device))\n",
    "        feat = pool_mean(out.last_hidden_state, batch[\"attention_mask\"].to(device))\n",
    "        z    = head(feat, return_feat=True)  # (B,384), already L2-normalized\n",
    "    all_chunks.append(z.cpu().numpy())\n",
    "\n",
    "Z = np.vstack(all_chunks)\n",
    "Z = l2_normalize(Z)  # idempotent but safe\n",
    "np.save(os.path.join(CFG[\"outdir\"], \"detective_emb_384.npy\"), Z)\n",
    "np.save(os.path.join(CFG[\"outdir\"], \"train_idx.npy\"), train_idx)\n",
    "np.save(os.path.join(CFG[\"outdir\"], \"val_idx.npy\"),   val_idx)\n",
    "\n",
    "with open(os.path.join(CFG[\"outdir\"], \"Detective_report.json\"), \"w\") as f:\n",
    "    json.dump({\"best_AvgRec\": float(best_sel),\n",
    "               \"val_metrics\": state[\"val_metrics\"],\n",
    "               \"ckpt\": ckpt_path}, f, indent=2)\n",
    "\n",
    "print(\"Embeddings saved to:\", os.path.join(CFG[\"outdir\"], \"text_embeddings_detective.npy\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
