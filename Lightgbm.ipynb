{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a07818f",
   "metadata": {},
   "source": [
    "# Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "EMBEDDING_LLM = \"data/text_embeddings.npy\"\n",
    "DATA_FILE = \"data/data.csv\"\n",
    "\n",
    "EMBEDDING_TFIDF = \"data/text_embeddings_tfidf.npy\"\n",
    "EMBEDDING_DETECTIVE = \"data/detective_emb_384.npy\"\n",
    "\n",
    "X_LLM = np.load(EMBEDDING_LLM)\n",
    "X_TFIDF = np.load(EMBEDDING_TFIDF)\n",
    "X_DETECTIVE = np.load(EMBEDDING_DETECTIVE)\n",
    "\n",
    "Y = pd.read_csv(DATA_FILE)[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd0fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape: (10000, 384), label: [0 1]\n",
      "Label Distribution:\n",
      "  Label 0: 6455 samples (64.55%)\n",
      "  Label 1: 3545 samples (35.45%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"embedding shape: {X.shape}, label: {np.unique(y)}\")\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "label_dist = dict(zip(unique, counts))\n",
    "print(\"Label Distribution:\")\n",
    "for label, count in label_dist.items():\n",
    "    percent = count / counts.sum() * 100\n",
    "    print(f\"  Label {label}: {count} samples ({percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9000e",
   "metadata": {},
   "source": [
    "### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c099588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings, re\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=UserWarning,\n",
    "    message=r\"X does not have valid feature names.*\"\n",
    ")\n",
    "\n",
    "# ============== Configurable Section ==============\n",
    "PARAM_GRID_SVC = {\n",
    "    \"num_leaves\": [31, 63, 127],\n",
    "    \"min_data_in_leaf\": [20, 50, 100],\n",
    "    \"learning_rate\": [0.02, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "OUTER_K = 10\n",
    "INNER_K = 3\n",
    "SEED = 42\n",
    "POS_LABEL = 0\n",
    "\n",
    "# ---- Build Model ----\n",
    "def make_svc(params):\n",
    "    # Which hyperparameters are allowed (ignore extra parameters)\n",
    "    allowed = {\"num_leaves\", \"min_data_in_leaf\", \"learning_rate\"}\n",
    "    # Keep only keys in 'allowed' and store in a new dictionary 'kwargs'\n",
    "    kwargs = {k: v for k, v in params.items() if k in allowed}\n",
    "    return LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        data_sample_strategy=\"goss\",  # Gradient-based One-Side Sampling\n",
    "        feature_fraction=0.8,         # Fraction of features used per iteration\n",
    "        force_col_wise=True,\n",
    "        verbosity=-1,\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "\n",
    "        min_data_in_leaf=kwargs[\"min_data_in_leaf\"],\n",
    "        num_leaves=kwargs[\"num_leaves\"],\n",
    "        learning_rate=kwargs[\"learning_rate\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# ======================================\n",
    "\n",
    "\n",
    "# ---- k-fold indices ----\n",
    "def simple_kfold_indices(n_samples, k, rng):\n",
    "    indices = np.arange(n_samples)\n",
    "    rng.shuffle(indices)\n",
    "    # Indices contained in each of the k folds\n",
    "    return np.array_split(indices, k)\n",
    "\n",
    "\n",
    "# ---- Evaluation metrics ----\n",
    "def confusion_matrix_binary(y_true, y_pred, pos=POS_LABEL):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    tp = int(np.sum((y_true == pos) & (y_pred == pos)))\n",
    "    fp = int(np.sum((y_true != pos) & (y_pred == pos)))\n",
    "    tn = int(np.sum((y_true != pos) & (y_pred != pos)))\n",
    "    fn = int(np.sum((y_true == pos) & (y_pred != pos)))\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def precision(tp, fp, tn, fn):\n",
    "    denom = tp + fp\n",
    "    return tp / denom if denom > 0 else 0.0\n",
    "\n",
    "def recall(tp, fp, tn, fn):\n",
    "    denom = tp + fn\n",
    "    return tp / denom if denom > 0 else 0.0\n",
    "\n",
    "def accuracy(tp, fp, tn, fn):\n",
    "    total = tp + fp + tn + fn\n",
    "    return (tp + tn) / total if total > 0 else 0.0\n",
    "\n",
    "def f1(tp, fp, tn, fn):\n",
    "    p = precision(tp, fp, tn, fn)\n",
    "    r = recall(tp, fp, tn, fn)\n",
    "    denom = p + r\n",
    "    return 2 * p * r / denom if denom > 0 else 0.0\n",
    "\n",
    "def compute_metrics(y_true, y_pred, pos=POS_LABEL):\n",
    "    tp, fp, tn, fn = confusion_matrix_binary(y_true, y_pred, pos)\n",
    "    return {\n",
    "        \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn,\n",
    "        \"precision\": precision(tp, fp, tn, fn),\n",
    "        \"recall\": recall(tp, fp, tn, fn),\n",
    "        \"accuracy\": accuracy(tp, fp, tn, fn),\n",
    "        \"f1\": f1(tp, fp, tn, fn),\n",
    "    }\n",
    "\n",
    "# ---- Generate all parameter combinations ----\n",
    "def param_grid_iter(param_grid):\n",
    "    keys = list(param_grid.keys())\n",
    "    for values in product(*[param_grid[k] for k in keys]):\n",
    "        yield dict(zip(keys, values))\n",
    "\n",
    "\n",
    "# ---- Inner cross-validation: select best parameters ----\n",
    "def inner_cv_select_params(X, y, train_idx, inner_k, param_grid, rng, make_model_fn):\n",
    "    # On the given training samples (train_idx), perform inner_k-fold cross-validation \n",
    "    # to evaluate all candidate hyperparameter combinations in param_grid\n",
    "\n",
    "    # len(folds) equals inner_k, i.e., inner_k groups\n",
    "    folds = simple_kfold_indices(len(train_idx), inner_k, rng)\n",
    "    folds = [train_idx[f] for f in folds]  # Convert relative indices to global indices\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_param = None\n",
    "\n",
    "    for params in param_grid_iter(param_grid):\n",
    "        fold_scores = []\n",
    "        for f in range(inner_k):\n",
    "            val_idx = folds[f]\n",
    "            tr_idx = np.concatenate([folds[j] for j in range(inner_k) if j != f])\n",
    "\n",
    "            model = make_model_fn(params)\n",
    "            model.fit(X[tr_idx], y[tr_idx])\n",
    "            pred = model.predict(X[val_idx])\n",
    "            # Use F1 as validation score\n",
    "            tp, fp, tn, fn = confusion_matrix_binary(y[val_idx], pred, POS_LABEL)\n",
    "            fold_scores.append(f1(tp, fp, tn, fn))\n",
    "        \n",
    "        # Core comparison: update best only if the average F1 is higher\n",
    "        avg_f1 = float(np.mean(fold_scores))\n",
    "        if avg_f1 > best_score:\n",
    "            best_score = avg_f1\n",
    "            best_param = params\n",
    "\n",
    "    return best_param\n",
    "\n",
    "\n",
    "# ---- Nested cross-validation ----\n",
    "def nested_cv(\n",
    "    X, y,\n",
    "    outer_k=OUTER_K,\n",
    "    inner_k=INNER_K,\n",
    "    param_grid=PARAM_GRID_SVC,\n",
    "    make_model_fn=make_svc,\n",
    "    seed=SEED\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    folds = simple_kfold_indices(len(X), outer_k, rng)\n",
    "\n",
    "    outer_metrics = []            # Metrics dictionary for each fold\n",
    "    chosen_params_each_fold = []  # Best hyperparameters for each fold\n",
    "    conf_sums = {\"tp\":0, \"fp\":0, \"tn\":0, \"fn\":0}\n",
    "\n",
    "    for i in range(outer_k):\n",
    "        test_idx = folds[i]\n",
    "        train_idx = np.concatenate([folds[j] for j in range(outer_k) if j != i])\n",
    "\n",
    "        # Inner loop: use F1 to select the best hyperparameters\n",
    "        best_param = inner_cv_select_params(X, y, train_idx, inner_k, param_grid, rng, make_model_fn)\n",
    "        chosen_params_each_fold.append(best_param)\n",
    "\n",
    "        # Outer loop: train and evaluate metrics on the test fold\n",
    "        model = make_model_fn(best_param)\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        pred = model.predict(X[test_idx])\n",
    "\n",
    "        mets = compute_metrics(y[test_idx], pred, POS_LABEL)\n",
    "        outer_metrics.append(mets)\n",
    "\n",
    "        # Accumulate confusion matrix counts\n",
    "        for k in (\"tp\",\"fp\",\"tn\",\"fn\"):\n",
    "            conf_sums[k] += mets[k]\n",
    "\n",
    "        print(f\"[Outer Fold {i+1}/{outer_k}] \"\n",
    "              f\"best_params={best_param} | \"\n",
    "              f\"Acc={mets['accuracy']:.4f} P={mets['precision']:.4f} \"\n",
    "              f\"R={mets['recall']:.4f} F1={mets['f1']:.4f} | \"\n",
    "              f\"Confusion(TP/FP/TN/FN)=({mets['tp']},{mets['fp']},{mets['tn']},{mets['fn']})\")\n",
    "\n",
    "    # Compute mean and standard deviation across folds\n",
    "    def agg_mean_std(key):\n",
    "        vals = np.array([m[key] for m in outer_metrics], dtype=float)\n",
    "        return float(vals.mean()), float(vals.std())\n",
    "\n",
    "    mean_acc, std_acc = agg_mean_std(\"accuracy\")\n",
    "    mean_p, std_p = agg_mean_std(\"precision\")\n",
    "    mean_r, std_r = agg_mean_std(\"recall\")\n",
    "    mean_f1, std_f1 = agg_mean_std(\"f1\")\n",
    "\n",
    "    print(\"\\n=== Final (Outer CV) Summary ===\")\n",
    "    print(f\"Confusion Matrix Sum over folds: TP={conf_sums['tp']} FP={conf_sums['fp']} TN={conf_sums['tn']} FN={conf_sums['fn']}\")\n",
    "    print(f\"Accuracy : mean={mean_acc:.4f}, std={std_acc:.4f}\")\n",
    "    print(f\"Precision: mean={mean_p:.4f},  std={std_p:.4f}\")\n",
    "    print(f\"Recall   : mean={mean_r:.4f},  std={std_r:.4f}\")\n",
    "    print(f\"F1-score : mean={mean_f1:.4f}, std={std_f1:.4f}\")\n",
    "\n",
    "    # Count how many times each hyperparameter combination was chosen (for display)\n",
    "    selections = Counter([tuple(sorted(p.items())) for p in chosen_params_each_fold])\n",
    "    print(\"\\n=== Chosen Hyperparameters Across Folds ===\")\n",
    "    for combo, count in selections.items():\n",
    "        print(f\"{dict(combo)}: chosen {count} times\")\n",
    "\n",
    "    return {\n",
    "        \"outer_metrics\": outer_metrics,                      # Full metrics per fold\n",
    "        \"confusion_sum\": conf_sums,                          # Aggregated confusion matrix\n",
    "        \"mean_std\": {                                        # Mean and std of each metric\n",
    "            \"accuracy\": (mean_acc, std_acc),\n",
    "            \"precision\": (mean_p, std_p),\n",
    "            \"recall\": (mean_r, std_r),\n",
    "            \"f1\": (mean_f1, std_f1),\n",
    "        },\n",
    "        \"chosen_params_each_fold\": chosen_params_each_fold,  # Best hyperparameters for each fold\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d105e",
   "metadata": {},
   "source": [
    "## MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26895b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Outer Fold 1/10] best_params={'num_leaves': 31, 'min_data_in_leaf': 100, 'learning_rate': 0.02} | Acc=0.7020 P=0.7293 R=0.8819 F1=0.7984 | Confusion(TP/FP/TN/FN)=(590,219,112,79)\n",
      "[Outer Fold 2/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7210 P=0.7379 R=0.8973 F1=0.8098 | Confusion(TP/FP/TN/FN)=(594,211,127,68)\n",
      "[Outer Fold 3/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 50, 'learning_rate': 0.02} | Acc=0.7140 P=0.7289 R=0.8960 F1=0.8038 | Confusion(TP/FP/TN/FN)=(586,218,128,68)\n",
      "[Outer Fold 4/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7100 P=0.7212 R=0.8960 F1=0.7992 | Confusion(TP/FP/TN/FN)=(577,223,133,67)\n",
      "[Outer Fold 5/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7010 P=0.7085 R=0.8901 F1=0.7890 | Confusion(TP/FP/TN/FN)=(559,230,142,69)\n",
      "[Outer Fold 6/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.6960 P=0.7028 R=0.9005 F1=0.7895 | Confusion(TP/FP/TN/FN)=(570,241,126,63)\n",
      "[Outer Fold 7/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7030 P=0.7241 R=0.8896 F1=0.7984 | Confusion(TP/FP/TN/FN)=(588,224,115,73)\n",
      "[Outer Fold 8/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 50, 'learning_rate': 0.02} | Acc=0.7010 P=0.7120 R=0.8936 F1=0.7925 | Confusion(TP/FP/TN/FN)=(571,231,130,68)\n",
      "[Outer Fold 9/10] best_params={'num_leaves': 63, 'min_data_in_leaf': 50, 'learning_rate': 0.02} | Acc=0.7180 P=0.7206 R=0.9033 F1=0.8017 | Confusion(TP/FP/TN/FN)=(570,221,148,61)\n",
      "[Outer Fold 10/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.1} | Acc=0.6840 P=0.6973 R=0.8864 F1=0.7806 | Confusion(TP/FP/TN/FN)=(562,244,122,72)\n",
      "\n",
      "=== Final (Outer CV) Summary ===\n",
      "Confusion Matrix Sum over folds: TP=5767 FP=2262 TN=1283 FN=688\n",
      "Accuracy : mean=0.7050, std=0.0105\n",
      "Precision: mean=0.7183,  std=0.0122\n",
      "Recall   : mean=0.8935,  std=0.0062\n",
      "F1-score : mean=0.7963, std=0.0080\n",
      "\n",
      "=== Chosen Hyperparameters Across Folds ===\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 100, 'num_leaves': 31}: chosen 1 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 20, 'num_leaves': 127}: chosen 5 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 50, 'num_leaves': 127}: chosen 2 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 50, 'num_leaves': 63}: chosen 1 times\n",
      "{'learning_rate': 0.1, 'min_data_in_leaf': 20, 'num_leaves': 127}: chosen 1 times\n",
      "(0.7962785693920866, 0.008048037236589546)\n"
     ]
    }
   ],
   "source": [
    "results = nested_cv(X_LLM, Y)\n",
    "print(results[\"mean_std\"][\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2b4c6",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "059764ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Outer Fold 1/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7430 P=0.7588 R=0.9028 F1=0.8246 | Confusion(TP/FP/TN/FN)=(604,192,139,65)\n",
      "[Outer Fold 2/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7090 P=0.7339 R=0.8792 F1=0.8000 | Confusion(TP/FP/TN/FN)=(582,211,127,80)\n",
      "[Outer Fold 3/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7300 P=0.7382 R=0.9098 F1=0.8151 | Confusion(TP/FP/TN/FN)=(595,211,135,59)\n",
      "[Outer Fold 4/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7250 P=0.7327 R=0.9022 F1=0.8086 | Confusion(TP/FP/TN/FN)=(581,212,144,63)\n",
      "[Outer Fold 5/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.05} | Acc=0.7170 P=0.7143 R=0.9156 F1=0.8025 | Confusion(TP/FP/TN/FN)=(575,230,142,53)\n",
      "[Outer Fold 6/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7260 P=0.7292 R=0.9021 F1=0.8065 | Confusion(TP/FP/TN/FN)=(571,212,155,62)\n",
      "[Outer Fold 7/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7360 P=0.7442 R=0.9153 F1=0.8209 | Confusion(TP/FP/TN/FN)=(605,208,131,56)\n",
      "[Outer Fold 8/10] best_params={'num_leaves': 63, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.7160 P=0.7255 R=0.8936 F1=0.8008 | Confusion(TP/FP/TN/FN)=(571,216,145,68)\n",
      "[Outer Fold 9/10] best_params={'num_leaves': 63, 'min_data_in_leaf': 50, 'learning_rate': 0.02} | Acc=0.7140 P=0.7220 R=0.8891 F1=0.7969 | Confusion(TP/FP/TN/FN)=(561,216,153,70)\n",
      "[Outer Fold 10/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.6980 P=0.7065 R=0.8959 F1=0.7900 | Confusion(TP/FP/TN/FN)=(568,236,130,66)\n",
      "\n",
      "=== Final (Outer CV) Summary ===\n",
      "Confusion Matrix Sum over folds: TP=5813 FP=2144 TN=1401 FN=642\n",
      "Accuracy : mean=0.7214, std=0.0126\n",
      "Precision: mean=0.7305,  std=0.0141\n",
      "Recall   : mean=0.9005,  std=0.0109\n",
      "F1-score : mean=0.8066, std=0.0103\n",
      "\n",
      "=== Chosen Hyperparameters Across Folds ===\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 20, 'num_leaves': 127}: chosen 7 times\n",
      "{'learning_rate': 0.05, 'min_data_in_leaf': 20, 'num_leaves': 127}: chosen 1 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 20, 'num_leaves': 63}: chosen 1 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 50, 'num_leaves': 63}: chosen 1 times\n",
      "(0.8065878476561169, 0.01033089401936429)\n"
     ]
    }
   ],
   "source": [
    "results = nested_cv(X_TFIDF, Y)\n",
    "print(results[\"mean_std\"][\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a12f9fb",
   "metadata": {},
   "source": [
    "## DeTeCtive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a2ea97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Outer Fold 1/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.1} | Acc=0.8160 P=0.8551 R=0.8729 F1=0.8639 | Confusion(TP/FP/TN/FN)=(584,99,232,85)\n",
      "[Outer Fold 2/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.1} | Acc=0.8280 P=0.8646 R=0.8776 F1=0.8711 | Confusion(TP/FP/TN/FN)=(581,91,247,81)\n",
      "[Outer Fold 3/10] best_params={'num_leaves': 31, 'min_data_in_leaf': 100, 'learning_rate': 0.02} | Acc=0.8240 P=0.8525 R=0.8838 F1=0.8679 | Confusion(TP/FP/TN/FN)=(578,100,246,76)\n",
      "[Outer Fold 4/10] best_params={'num_leaves': 127, 'min_data_in_leaf': 20, 'learning_rate': 0.02} | Acc=0.8070 P=0.8540 R=0.8447 F1=0.8493 | Confusion(TP/FP/TN/FN)=(544,93,263,100)\n",
      "[Outer Fold 5/10] best_params={'num_leaves': 63, 'min_data_in_leaf': 100, 'learning_rate': 0.02} | Acc=0.7940 P=0.8276 R=0.8487 F1=0.8381 | Confusion(TP/FP/TN/FN)=(533,111,261,95)\n",
      "[Outer Fold 6/10] best_params={'num_leaves': 63, 'min_data_in_leaf': 20, 'learning_rate': 0.1} | Acc=0.8320 P=0.8517 R=0.8894 F1=0.8702 | Confusion(TP/FP/TN/FN)=(563,98,269,70)\n",
      "[Outer Fold 7/10] best_params={'num_leaves': 31, 'min_data_in_leaf': 100, 'learning_rate': 0.02} | Acc=0.8180 P=0.8426 R=0.8911 F1=0.8662 | Confusion(TP/FP/TN/FN)=(589,110,229,72)\n",
      "[Outer Fold 8/10] best_params={'num_leaves': 63, 'min_data_in_leaf': 100, 'learning_rate': 0.02} | Acc=0.8100 P=0.8356 R=0.8748 F1=0.8547 | Confusion(TP/FP/TN/FN)=(559,110,251,80)\n",
      "[Outer Fold 9/10] best_params={'num_leaves': 31, 'min_data_in_leaf': 100, 'learning_rate': 0.02} | Acc=0.8120 P=0.8281 R=0.8859 F1=0.8560 | Confusion(TP/FP/TN/FN)=(559,116,253,72)\n",
      "[Outer Fold 10/10] best_params={'num_leaves': 63, 'min_data_in_leaf': 100, 'learning_rate': 0.02} | Acc=0.8070 P=0.8408 R=0.8580 F1=0.8493 | Confusion(TP/FP/TN/FN)=(544,103,263,90)\n",
      "\n",
      "=== Final (Outer CV) Summary ===\n",
      "Confusion Matrix Sum over folds: TP=5634 FP=1031 TN=2514 FN=821\n",
      "Accuracy : mean=0.8148, std=0.0107\n",
      "Precision: mean=0.8453,  std=0.0117\n",
      "Recall   : mean=0.8727,  std=0.0159\n",
      "F1-score : mean=0.8587, std=0.0104\n",
      "\n",
      "=== Chosen Hyperparameters Across Folds ===\n",
      "{'learning_rate': 0.1, 'min_data_in_leaf': 20, 'num_leaves': 127}: chosen 2 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 100, 'num_leaves': 31}: chosen 3 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 20, 'num_leaves': 127}: chosen 1 times\n",
      "{'learning_rate': 0.02, 'min_data_in_leaf': 100, 'num_leaves': 63}: chosen 3 times\n",
      "{'learning_rate': 0.1, 'min_data_in_leaf': 20, 'num_leaves': 63}: chosen 1 times\n",
      "(0.8586696439131293, 0.010372778079327065)\n"
     ]
    }
   ],
   "source": [
    "results = nested_cv(X_DETECTIVE, Y)\n",
    "print(results[\"mean_std\"][\"f1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
